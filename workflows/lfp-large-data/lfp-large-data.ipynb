{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3230927-63c7-4e3f-82c6-2be7afbd5aa8",
   "metadata": {},
   "source": [
    "# Large data handling example\n",
    "\n",
    "This is an example of how to read and render a 'large' quantity of data, whether locally or remote, without having to copy and/or rechunk the data into a more suitable data format. Data chosen is from a Neuropixels probe's local field potential (LFP) data from one of the Allen Institute for Brain Science's AllenSDK example sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f9edd-459f-471a-b89a-be4b6cf280bc",
   "metadata": {},
   "source": [
    "## Obtain LFP data\n",
    "\n",
    "First download the required data using the AllenSDK. This will be cached locally, so the first time this notebook is run will be slow as it downloads the data, and the second and subsequent times will be much faster. The data file is an NWB file which is an HDF5 file with a particular internal format. The data file is downloaded locally for ease of experimenting with, but this workflow also supports the data file begin accessed remotely so that it could, for example, be in an s3 bucket and we would only read the chunks that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609fd33-1a18-44ad-91fb-42487be550f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b82d93-36bd-4d83-aad4-cd8d6e9e6e17",
   "metadata": {},
   "source": [
    "Store the AllenSDK cache somewhere sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb1dc3-c75a-4e22-a405-2e3c309bea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_cache_dir = os.path.expanduser(os.path.join(\"~\", \"allensdk_cache\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc2fc1-8c75-4674-a9cc-daef3fcc4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = EcephysProjectCache.from_warehouse(manifest=os.path.join(local_cache_dir, \"manifest.json\"))\n",
    "sessions = cache.get_session_table()\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e6a1d-abbb-4484-a3f1-253133d6919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the very first session.\n",
    "session_id = sessions.index.values[0]\n",
    "session = cache.get_session_data(session_id)\n",
    "session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf7d76-56bc-4f48-9d5a-0b140fa0ee3e",
   "metadata": {},
   "source": [
    "Each session contains a number of probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e4f32-86c9-4395-a23a-ab624c2968a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e50cfb-3238-421e-920c-09984823682c",
   "metadata": {},
   "source": [
    "We will take the first probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665b6f9-6a76-408a-a759-1762d80c7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_id = session.probes.index.values[0]\n",
    "# lfp = session.get_lfp(probe_id) # This will load 2 GB of LFP data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5ea11-7f34-439b-b885-86a6f99322d6",
   "metadata": {},
   "source": [
    "The NWB file that we want is now stored locally. We need its filename to read it directly so that we don't have to use the AllenSDK any more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04f941-afeb-4a1a-98b7-3dbfc479391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_nwb_filename = os.path.join(local_cache_dir, f\"session_{session_id}\", f\"probe_{probe_id}_lfp.nwb\")\n",
    "lfp_nwb_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117f8e1-e911-4fd6-8892-751a400677e7",
   "metadata": {},
   "source": [
    "Check the size of the file, should be about 2 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84343e33-e1f1-45d6-a80c-204ab4b8aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"File size {os.path.getsize(lfp_nwb_filename) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fa45d-2159-4ac9-bf8d-76ff2f78dd09",
   "metadata": {},
   "source": [
    "##Â Read the NWB file\n",
    "\n",
    "NWB files are stored in HDF5 format, so we can read it using h5py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb9c186-6be3-4cbb-bca8-db78a5584595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(lfp_nwb_filename, \"r\")\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd25a2-c286-42d8-9b57-5d6025c43818",
   "metadata": {},
   "source": [
    "Top-level keys in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc7c32-f9e7-495a-acba-560197e60a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb352dd2-83ce-49ef-8722-0262424051a1",
   "metadata": {},
   "source": [
    "There is lots of useful information here which can be examined by walking the tree structure. The LFP data is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9816d-bef8-4f67-83bc-752790e469a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_data = f[f\"acquisition/probe_{probe_id}_lfp/probe_{probe_id}_lfp_data/data\"]\n",
    "lfp_data.shape, lfp_data.dtype, lfp_data.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4edccfb-7cfd-4966-8ce0-3d1839d5dffb",
   "metadata": {},
   "source": [
    "The first dimension is time and the second is channel. The corresponding timestamps are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc5d4d-ae06-40e6-9b82-9e628b1ed3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_time = f[f\"acquisition/probe_{probe_id}_lfp/probe_{probe_id}_lfp_data/timestamps\"]\n",
    "lfp_time.shape, lfp_time.dtype, lfp_time.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e661e5-5cfa-4228-9f3e-7e0b4c030fb4",
   "metadata": {},
   "source": [
    "There is also metadata for each array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd094247-015b-40d3-959f-c4238e00786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([item for item in lfp_data.attrs.items()], [item for item in lfp_time.attrs.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e52c74b-aa7a-4340-8ee9-511155e041d7",
   "metadata": {},
   "source": [
    "although we are aren't using the metadata in this example workflow yet.\n",
    "\n",
    "The chunk sizes are important here, as a chunk is the smallest unit of data that we can read and process. First note that the chunk sizes for the LFP data and timestamps are different, which is unfortunate. The chunk size of the data is quite small (41859*4 bytes = 164 kB) and the number of chunks of LFP data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a34f14-1f77-4188-aeb5-38925f717a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of chunks\", [s/c for s, c in zip(lfp_data.shape, lfp_data.chunks)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23276d83-e891-40b0-89d2-4cde5a3f0251",
   "metadata": {},
   "source": [
    "So there are 256*93 = 23808 chunks in total. Possibly the chunk size in the time dimension has been chosen so that there are 256 chunks in this dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b98e9a-4e6f-4cff-b4eb-e775af8d20f2",
   "metadata": {},
   "source": [
    "# Create kerchunk reference JSON file\n",
    "\n",
    "Now we use kerchunk to create a JSON file that separately refers to each chunk of LFP data in the NWB file and when loaded using zarr this behaves like a lazy-loaded 2D array without having to make a new copy of the data. We are constrained to use the same chunk size for the LFP data. We encode the 1D timestamp array within the JSON file; an alternative would be to reference the timestamps in the original NWB file but then there is the problem of their chunks being a different size to the LFP data. There are handy functions in kerchunk to process the whole of the NWB file, but we want to change the keys (i.e. xarray variable names) under which they are stored so we need to do some extra processing ourselves. The code for this is in the `nwb_kerchunk.py` Python file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7801dc1-4baa-4200-aca2-73ea90453074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_kerchunk import nwb_kerchunk\n",
    "\n",
    "kerchunk_json_filename = \"lfp.json\"\n",
    "nwb_kerchunk(probe_id, lfp_nwb_filename, kerchunk_json_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a8a9c-3dc4-46ae-a72c-c294c4a040fd",
   "metadata": {},
   "source": [
    "# Load LFP data as an xarray using zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba906854-32af-4583-ad4d-999092439fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cd6bb-ed4a-4a13-87e3-4eb20f3d68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\"reference\", fo=kerchunk_json_filename)\n",
    "xr_ds = xr.open_dataset(\n",
    "    fs.get_mapper(),\n",
    "    engine=\"zarr\",\n",
    "    backend_kwargs={\"consolidated\": False, \"mask_and_scale\": False}\n",
    ")\n",
    "xr_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d16cf0-19c3-40a4-b20d-24fabdac2662",
   "metadata": {},
   "source": [
    "To show this data is lazy-accessed, calculate the min and max of the first three channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2bda9-c323-4812-881c-e4adaae588d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_ds.lfp[:, :3].min(axis=0).compute(), xr_ds.lfp[:, :3].max(axis=0).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff9e36-b2ea-4bb4-beb3-270df35f39ae",
   "metadata": {},
   "source": [
    "## Visualize using Datashader and Bokeh\n",
    "\n",
    "Here is an example of how to interactively visualize the LFP data using just Datashader and Bokeh. Think of the code here as a simple HoloViews that has a callback when you try to zoom the Bokeh image that calls Datashader to re-datashade the new zoomed bounding box.\n",
    "\n",
    "First let's look at a shorter timeseries, all channels (otherwise we have to load all of the data to obtain the min and max for each channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc23cee-f6eb-4aa3-a8fb-1546539aa278",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_ds = xr_ds.isel(time=slice(0, 100_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c445bb-e39d-4e40-8127-7accd75407b6",
   "metadata": {},
   "source": [
    "Then calculate a new `DataArray` containing offset and scaled data, so that each channel is displayed offset with respect to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee79195-4444-42a6-b480-2ca0ad632400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "channel_min = xr_ds[\"lfp\"].min(axis=0)\n",
    "channel_max = xr_ds[\"lfp\"].max(axis=0)\n",
    "xr_ds[\"lfp_subplot\"] = (xr_ds[\"lfp\"] - channel_min) / (channel_max - channel_min) + np.arange(xr_ds.dims[\"channel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6c257-9bda-45b0-9fab-a3c68ba12bf9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Now create the Bokeh document with a Python callback to process RangesUpdate events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945bd23-9719-44cd-83cc-6133752b9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.events import RangesUpdate\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "import datashader as ds\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "def bkapp(doc):\n",
    "    width = 1200\n",
    "    height = 800\n",
    "    canvas = ds.Canvas(plot_width=width, plot_height=height)\n",
    "    agg = canvas.line(source=xr_ds, x=\"time\", y=\"lfp_subplot\", agg=ds.any())\n",
    "    \n",
    "    initialised = False\n",
    "    x_range = agg.x_range\n",
    "    y_range = agg.y_range\n",
    "    tools = \"pan, box_zoom, reset\"\n",
    "    p = figure(width=width, height=height, x_range=x_range, y_range=y_range, tools=tools)\n",
    "    \n",
    "    cds = ColumnDataSource(data=dict(\n",
    "        image=[agg.data], x=[x_range[0]], y=[y_range[0]],\n",
    "        dw=[x_range[1]-x_range[0]], dh=[y_range[1]-y_range[0]],\n",
    "    ))\n",
    "    \n",
    "    im = p.image(source=cds, image=\"image\", palette=[\"white\", \"blue\"], x=\"x\", y=\"y\", dw=\"dw\", dh=\"dh\")\n",
    "    \n",
    "    def callback(event):\n",
    "        global width, height, initialised\n",
    "        if not initialised:\n",
    "            #Â First call fixes datashader's canvas size to match the inner size of the figure\n",
    "            width = p.inner_width\n",
    "            height = p.inner_height\n",
    "            initialised = True\n",
    "    \n",
    "        # Recalculate and render new image.\n",
    "        canvas = ds.Canvas(plot_width=width, plot_height=height, x_range=(event.x0, event.x1), y_range=(event.y0, event.y1))\n",
    "        agg = canvas.line(source=xr_ds, x=\"time\", y=\"lfp_subplot\", agg=ds.any())\n",
    "        cds.data = dict(image=[agg.data], x=[event.x0], y=[event.y0], dw=[event.x1-event.x0], dh=[event.y1-event.y0])\n",
    "    \n",
    "    p.on_event(RangesUpdate, callback)\n",
    "    \n",
    "    doc.add_root(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e843f-b77f-4454-9430-a1c8a7a376b7",
   "metadata": {},
   "source": [
    "Now run the Bokeh app and zoom and pan in the usual manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346dbbcd-ea69-42e4-a546-b723c8644a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(bkapp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadda99c-1b81-4bc9-9d9e-6e0198725e73",
   "metadata": {},
   "source": [
    "## Multiple probes per dataset\n",
    "\n",
    "In principle it is possible to combine the LFP data from multiple probes into a single kerchunked JSON file and hence a single zarr-loaded `xarray.Dataset`. The LFP would have a shape of `(nprobe, ntime, nchannel)`. The `time` for each probe is different, so the time coordinates would have to be 2D of shape `(nprobe, ntime)`. A bigger problem is that the LFP data of each channel has different chunk sizes. If they were the same then this approach would work, but if not then it is not possible. Dask chunking of multidimensional arrays allows the chunksize to vary as a function of its own dimension, but not as a function of other dimensions. Hence this idea is only possible if we copy the NWB data with it rechunked to a common chunk size. In future it would be preferable if the decision on how to chunk such data when it is stored takes this into account and uses a common chunk size for each probe in a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db61f59-7552-40ee-9376-5e206cb5b57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
