{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Viewer\n",
    "![status](https://img.shields.io/badge/status-in%20progress-orange)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./assets/230524_eeg-viewer.png\" alt=\"eeg viewer preview\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This workflow is intended to demonstrate the visualization of a set of 1D EEG timeseries with HoloViz and Bokeh tools.\n",
    "\n",
    "For details specific to this workflow, such as goals, specifications, and bottlenecks, please see this workflow's [readme](./readme_eeg-viewer.md).\n",
    "\n",
    "For a summary of EEG research, data, and software, please see [neuro/wiki/EEG-notes](https://github.com/holoviz-topics/neuro/wiki/EEG-notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Requirements</p>\n",
    "    <p>This workflow notebook requires the <a href=\"./environment.yml\">environment</a> specified in this workflow directory.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import holoviews as hv; hv.extension('bokeh')\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from neurodatagen.eeg import generate_eeg_powerlaw\n",
    "from scipy.stats import zscore\n",
    "import panel as pn; pn.extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate simulated data\n",
    "\n",
    "The `generate_eeg_powerlaw` function synthesizes EEG data as high-pass filtered pink noise power law time series by default. The function returns a 2D numpy array of synthetic EEG data (in microvolts) shaped as (number of channels, total samples), a 1D time array (in seconds), and a list of channel names. Parameters such as the high-pass filter factor (in Hz) and an amplitude scaling factor allow customization of the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 25\n",
    "n_seconds = 30\n",
    "fs = 512\n",
    "\n",
    "data, time, channels = generate_eeg_powerlaw(n_channels, n_seconds, fs)\n",
    "\n",
    "print(f'shape: {data.shape} (n_channels, samples) ')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize synthetic EEG data with minimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set vertical spacing for EEG traces to avoid visual overlap\n",
    "spacing = 1.2\n",
    "offset = np.max(np.abs(data)) * spacing\n",
    "\n",
    "# Create a hv.Curve element per chan.\n",
    "# Note: alternative is to call hv.Path once on offset-adjusted data, but \n",
    "# then we couldn't independently apply formating to the channels (which \n",
    "# we aren't doing yet, but we likely will in the future)\n",
    "channel_curves = []\n",
    "max_data = data.max()\n",
    "for i, channel_data in enumerate(data):\n",
    "    offset_data = channel_data + (i * offset)\n",
    "    max_data = max(offset_data.max(), max_data) # update max\n",
    "    channel_curves.append(\n",
    "        hv.Curve((time, offset_data), \"Time\").opts(\n",
    "            color=\"black\", line_width=1,\n",
    "            tools=[\"hover\", 'xwheel_zoom']))\n",
    "\n",
    "# Create mapping from yaxis location to ytick for each channel\n",
    "# so we can have categorical-style labeling on a continuous axis.\n",
    "# Note: this would/should change when we implement independent \n",
    "# coordinates.\n",
    "yticks = [(i * offset, ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "# Restrict pan/zoom bounds to data range. \n",
    "# TODO.. this does not yet restrict the RangeTool from going beyond these limits\n",
    "# TODO.. the zoom out will stop when it hits any single bound, and not continue zooming out in other directions/dims\n",
    "def set_bounds(fig, element):\n",
    "    fig.state.x_range.bounds = (time.min(), time.max())\n",
    "    fig.state.y_range.bounds = (data.min(), max_data)\n",
    "\n",
    "# Create an overlay of curves\n",
    "eeg_viewer = hv.Overlay(channel_curves, kdims=\"Channel\").opts(\n",
    "    width=800, height=600, padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\",\n",
    "    yticks=yticks, show_legend=False, hooks=[set_bounds])\n",
    "\n",
    "# Get the y positions of the yticks to use as yaxis of minimap image\n",
    "y_positions, _ = zip(*yticks)\n",
    "\n",
    "# Compute z-scores across time for each channel\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "# Generate the zscored image for the minimap using the y tick positions from the eeg_viewer\n",
    "minimap = hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\")\n",
    "\n",
    "# Style the minimap\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", colorbar=False, width=800, height=100, xlabel='', alpha=.5, yticks=[yticks[0], yticks[-1]],)\n",
    "\n",
    "# Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# (quirk: apply to just one eeg trace and it will apply to all. see HoloViews #4472)\n",
    "max_ch_disp = 10 # max channels to initially display\n",
    "max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "max_t_disp = 5 # max time to initially display\n",
    "RangeToolLink(minimap, list(eeg_viewer.values())[0], axes=[\"x\", \"y\"],\n",
    "              boundsx=(None, max_t_disp),\n",
    "              boundsy=(None, max_y_disp))\n",
    "\n",
    "# Display vertically\n",
    "layout = (eeg_viewer + minimap).cols(1).opts(shared_axes=False, merge_tools=False)\n",
    "pn.panel(layout).servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and plot real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
