{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991da59-7c7b-4116-8df3-3516d5e46490",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATE = True\n",
    "\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "from bokeh.models import HoverTool\n",
    "from holoviews import Dataset\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from scipy.stats import zscore\n",
    "\n",
    "hv.extension('bokeh')\n",
    "\n",
    "N_CHANNELS = 10\n",
    "N_SECONDS = 5\n",
    "SAMPLING_RATE = 200\n",
    "INIT_FREQ = 2  # Initial frequency in Hz\n",
    "FREQ_INC = 5  # Frequency increment\n",
    "AMPLITUDE = 1\n",
    "\n",
    "# Generate time and channel labels\n",
    "total_samples = N_SECONDS * SAMPLING_RATE\n",
    "time = np.linspace(0, N_SECONDS, total_samples)\n",
    "channels = [f'EEG {i}' for i in range(N_CHANNELS)]\n",
    "\n",
    "# Generate sine wave data\n",
    "data = np.array([AMPLITUDE * np.sin(2 * np.pi * (INIT_FREQ + i * FREQ_INC) * time)\n",
    "                     for i in range(N_CHANNELS)])\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Channel\", \"@channel\"),\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Amplitude\", \"$y ÂµV\")\n",
    "])\n",
    "\n",
    "annotation = hv.VSpan(1, 1.5).opts(color='yellow', alpha=.15) # example annotation (start, end) time\n",
    "\n",
    "channel_curves = []\n",
    "for channel, channel_data in zip(channels, data):\n",
    "    ds = Dataset((time, channel_data, channel), [\"Time\", \"Amplitude\", \"channel\"])\n",
    "    curve = hv.Curve(ds, \"Time\", [\"Amplitude\", \"channel\"], label=f'{channel}')\n",
    "    curve.opts(color=\"black\", line_width=1, subcoordinate_y=True, tools=[hover])\n",
    "    channel_curves.append(curve)\n",
    "\n",
    "if ANNOTATE:\n",
    "    eeg_viewer = (annotation * hv.Overlay(channel_curves, kdims=\"Channel\"))\n",
    "else:\n",
    "    eeg_viewer = hv.Overlay(channel_curves, kdims=\"Channel\")\n",
    "eeg_viewer = eeg_viewer.opts(padding=0,\n",
    "    xlabel=\"Time (s)\", ylabel=\"Channel\", show_legend=False, aspect=3, responsive=True,\n",
    ")\n",
    "\n",
    "y_positions = range(N_CHANNELS)\n",
    "yticks = [(i , ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "minimap = hv.Image((time, y_positions , z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\")\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", xlabel='Time (s)', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "    height=150, responsive=True, default_tools=[], clim=(-z_data.std(), z_data.std())\n",
    ")\n",
    "\n",
    "RangeToolLink(\n",
    "    minimap, eeg_viewer, axes=[\"x\", \"y\"],\n",
    "    boundsx=(None, 2), boundsy=(None, 6.5)\n",
    ")\n",
    "if ANNOTATE:\n",
    "    dashboard = (eeg_viewer + minimap * annotation).opts(merge_tools=False).cols(1)\n",
    "else:\n",
    "    dashboard = (eeg_viewer + minimap).opts(merge_tools=False).cols(1)\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced076e-b72b-4cb6-9cfc-6525c36d56df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
