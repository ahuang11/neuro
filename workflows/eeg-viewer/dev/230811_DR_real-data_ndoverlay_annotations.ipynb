{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Viewer\n",
    "![status](https://img.shields.io/badge/status-in%20progress-orange)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./assets/230524_eeg-viewer.png\" alt=\"eeg viewer preview\" width=\"450\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This workflow is intended to demonstrate the visualization of a set of 1D EEG timeseries with HoloViz and Bokeh tools.\n",
    "\n",
    "For details specific to this workflow, such as goals, specifications, and bottlenecks, please see this workflow's [readme](./readme_eeg-viewer.md).\n",
    "\n",
    "For a summary of EEG research, data, and software, please see [neuro/wiki/EEG-notes](https://github.com/holoviz-topics/neuro/wiki/EEG-notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Requirements</p>\n",
    "    <p>This workflow notebook requires the <a href=\"./environment.yml\">environment</a> specified in this workflow directory.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import mne\n",
    "\n",
    "from bokeh.models import HoverTool, WheelZoomTool\n",
    "import colorcet as cc\n",
    "import holoviews as hv; hv.extension('bokeh')\n",
    "from holoviews import Dataset\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from holoviews.operation.datashader import rasterize\n",
    "import panel as pn; pn.extension(template='material')\n",
    "\n",
    "from neurodatagen.eeg import generate_eeg_powerlaw\n",
    "from hvneuro import download_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data pipeline\n",
    "\n",
    "The `generate_eeg_powerlaw` function synthesizes EEG data as high-pass filtered pink noise power law time series by default. The function returns a 2D numpy array of synthetic EEG data (in microvolts) shaped as (number of channels, total samples), a 1D time array (in seconds), and a list of channel names. Parameters such as the high-pass filter factor (in Hz) and an amplitude scaling factor allow customization of the generated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 25\n",
    "n_seconds = 30\n",
    "fs = 512\n",
    "\n",
    "data, time, channels = generate_eeg_powerlaw(n_channels, n_seconds, fs)\n",
    "\n",
    "print(f'shape: {data.shape} (n_channels, samples) ')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_ch_disp = 10  # max channels to initially display\n",
    "max_t_disp = 3 # max time in seconds to initially display\n",
    "\n",
    "spacing = 5.5  # Spacing between channels\n",
    "offset = np.std(data) * spacing\n",
    "\n",
    "annotation = hv.VSpan(1, 2) # example annotation (start, end) time\n",
    "\n",
    "# Create a hv.Curve element per chan\n",
    "channel_curves = []\n",
    "max_data = data.max()\n",
    " \n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Channel\", \"@channel\"),\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Amplitude\", \"@original_amplitude ÂµV\")])\n",
    "\n",
    "for i, channel_data in enumerate(data):\n",
    "    offset_data = channel_data + (i * offset)\n",
    "    max_data = max(offset_data.max(), max_data) # update max\n",
    "    ds = Dataset((time, offset_data, channel_data, channels[i]), [\"Time\", \"Amplitude\", \"original_amplitude\", \"channel\"])\n",
    "    channel_curves.append(\n",
    "        hv.Curve(ds, \"Time\", [\"Amplitude\", \"original_amplitude\", \"channel\"]).opts(\n",
    "            color=\"black\", line_width=1,\n",
    "            tools=[hover, 'xwheel_zoom'], shared_axes=False))\n",
    "\n",
    "# Create mapping from yaxis location to ytick for each channel\n",
    "# so we can have categorical-style labeling on a continuous axis.\n",
    "# Note: this would/should change when we implement independent \n",
    "# coordinates.\n",
    "yticks = [(i * offset, ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "# Create an overlay of curves\n",
    "# TODO.. setting x/y_range bounds does not yet restrict the RangeTool from going beyond these limits\n",
    "# TODO.. the zoom out will stop when it hits any single bound, and not continue zooming out in other directions/dims\n",
    "eeg_viewer = (annotation * hv.Overlay(channel_curves, kdims=\"Channel\")).opts(\n",
    "    padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\", #default_tools=['hover', 'pan', 'box_zoom', 'save', 'reset'],\n",
    "    yticks=yticks, show_legend=False, aspect=1.5, responsive=True,\n",
    "    shared_axes=False, backend_opts={\n",
    "        \"x_range.bounds\": (time.min(), time.max()),\n",
    "        \"y_range.bounds\": (data.min(), max_data)})\n",
    "\n",
    "# Get the y positions of the yticks to use as yaxis of minimap image\n",
    "y_positions, _ = zip(*yticks)\n",
    "\n",
    "# Compute z-scores across time for each channel\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "# Generate the zscored image for the minimap using the y tiack positions from the eeg_viewer\n",
    "minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "\n",
    "# Style the minimap \n",
    "clim_mul = 1.2\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "    height=100, responsive=True, default_tools=[''], shared_axes=False, clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "    \n",
    "# Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# (quirk: apply to just one eeg trace and it will apply to all. see HoloViews #4472)\n",
    "max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "RangeToolLink(minimap, list(eeg_viewer.values())[0], axes=[\"x\", \"y\"],\n",
    "              boundsx=(None, max_t_disp),\n",
    "              boundsy=(None, max_y_disp))\n",
    "\n",
    "\n",
    "# layout = (eeg_viewer + minimap).cols(1).opts(shared_axes=False, merge_tools=False)\n",
    "# eeg_app = pn.Row(layout).servable() # too much spacing between plots in served app\n",
    "# eeg_app = pn.Column(pn.Row(eeg_viewer, min_height=500, sizing_mode='stretch_both'), minimap, sizing_mode='stretch_both')#.servable()#target='main') # BUG Panel #5315: rangetool is variably active in the bokeh toolbar on eeg viewer plot.. not respecting shared_axes=False\n",
    "\n",
    "# reverting approach because of the rangetool bug.. will deal with the spacing in the served app later\n",
    "eeg_app = pn.Column((eeg_viewer + minimap * annotation).cols(1), min_height=650).servable(target='main', title='EEG Viewer with HoloViz and Bokeh')\n",
    "eeg_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset is 2.6 MB on disk\n",
    "url = \"https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf?download\"\n",
    "local_data_path = \"../../data/\"\n",
    "\n",
    "# Will not download if already present at local_data_path\n",
    "local_file_path = download_file(url, local_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(local_file_path, preload=True)\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview the channel names, types, signal ranges, and uncompressed size\n",
    "raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean channel names, set sensor positions, and reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the channel names\n",
    "raw.rename_channels(lambda s: s.strip(\".\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # preview available montages that are shipped with MNE\n",
    "# mne.channels.get_builtin_montages(descriptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's use the standard 10-20\n",
    "# montage = mne.channels.make_standard_montage(\"standard_1020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the assigned positions of our data channels\n",
    "# raw.set_montage(montage, match_case=False)\n",
    "# sphere=(0, 0.015, 0, 0.099) #manually adjust the y origin coord and radius a bit\n",
    "# raw.plot_sensors(show_names=True, sphere=sphere);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-reference EEG data to the average over all recording channels\n",
    "raw.set_eeg_reference(\"average\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the data for plotting with bare numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = raw.times\n",
    "channels = raw.ch_names\n",
    "\n",
    "# get the EEG data (for this dataset, all channels are EEG anyways)\n",
    "eeg_indices = mne.pick_types(raw.info, eeg=True)\n",
    "data = raw.get_data(picks=eeg_indices, units={\"eeg\":\"uV\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial time of experiment\n",
    "orig_time = raw.annotations.orig_time\n",
    "\n",
    "# get annotations into pandas df\n",
    "annotations_df = raw.annotations.to_data_frame()\n",
    "\n",
    "# Ensure the 'onset' column is in UTC timezone\n",
    "annotations_df['onset'] = annotations_df['onset'].dt.tz_localize('UTC')\n",
    "\n",
    "annotations_df['start'] = (annotations_df['onset'] - orig_time).dt.total_seconds()\n",
    "annotations_df['end'] = annotations_df['start'] + annotations_df['duration']\n",
    "\n",
    "\n",
    "unique_descriptions = annotations_df['description'].unique()\n",
    "color_map = dict(zip(unique_descriptions, cc.glasbey))\n",
    "annotations_df['color'] = annotations_df['description'].map(color_map)\n",
    "\n",
    "annotations_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overlay of VSpan annotations based on the annotations dataframe\n",
    "annotation_elements = [hv.VSpan(row['start'], row['end']).opts(fill_color=row['color'], alpha=0.1) \n",
    "                       for _, row in annotations_df.iterrows()]\n",
    "annotations_overlay = hv.Overlay(annotation_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting constants and tools for the next plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_ch_disp = 10  # max channels to initially display\n",
    "max_t_disp = 5  # max time in seconds to initially display\n",
    "\n",
    "spacing = 2.5  # Spacing between channels\n",
    "offset = np.std(data) * spacing\n",
    "\n",
    "y_positions = np.arange(len(channels)) * offset\n",
    "yticks = list(zip(y_positions, channels))\n",
    "\n",
    "clim_spacing = 1.2 # color spacing for minimap\n",
    "\n",
    "hover = HoverTool(\n",
    "    tooltips=[\n",
    "        (\"Channel\", \"@channel\"),\n",
    "        (\"Time\", \"$x s\"),\n",
    "        (\"Amplitude\", \"@original_amplitude ÂµV\"),\n",
    "    ]\n",
    ")\n",
    "wheel = WheelZoomTool(\n",
    "    zoom_together=\"none\",\n",
    "    dimensions=\"width\",\n",
    "    maintain_focus=False,\n",
    ")\n",
    "tools = [\"save\", \"pan\", wheel, \"box_zoom\", \"reset\", hover]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the EEG viewer and combine with the annotation overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create eeg_viewer\n",
    "data_with_offset = data + (np.arange(len(data))[:, np.newaxis] * offset)\n",
    "max_data = data_with_offset.max()\n",
    "ds = hv.Dataset(\n",
    "    (channels, time, data_with_offset.T, data.T),\n",
    "    kdims=[\"channel\", \"Time\"],\n",
    "    # vdims=[\"Amplitude\", \"original_amplitude\"],  # Original amplitude does not yet work well with HoverTool in an overlay plot.\n",
    "    vdims=[\"Amplitude\"],\n",
    ")\n",
    "eeg_viewer = (\n",
    "    ds.to(hv.Curve, groupby=\"channel\")\n",
    "    .overlay()\n",
    "    .opts(hv.opts.Curve(color=\"black\", line_width=1, tools=[hover, \"xwheel_zoom\"]))\n",
    ")\n",
    "\n",
    "# Combine with annotations\n",
    "eeg_with_annotations = eeg_viewer\n",
    "\n",
    "# Style the EEG Viewer Overlay\n",
    "eeg_with_annotations = eeg_with_annotations.opts(\n",
    "    padding=0,\n",
    "    xlabel=\"Time (s)\",\n",
    "    ylabel=\"Channel\",\n",
    "    yticks=yticks,\n",
    "    show_legend=False,\n",
    "    aspect=1.5,\n",
    "    responsive=True,\n",
    "    shared_axes=False,\n",
    "    backend_opts={\n",
    "        \"x_range.bounds\": (time.min(), time.max()),\n",
    "        \"y_range.bounds\": (data.min(), max_data),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the minimap and [rasterize](https://holoviews.org/user_guide/Large_Data.html#holoviews-operations-for-datashading) it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute z-scores across time for each channel\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "# Generate the rasterized zscored image for the minimap using the y tiack positions from the eeg_viewer\n",
    "minimap = rasterize(\n",
    "    hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\")\n",
    ")\n",
    "\n",
    "# Style the minimap\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\",\n",
    "    colorbar=False,\n",
    "    xlabel=\"\",\n",
    "    alpha=0.5,\n",
    "    yticks=[yticks[0], yticks[-1]],\n",
    "    height=100,\n",
    "    responsive=True,\n",
    "    default_tools=[\"\"],\n",
    "    shared_axes=False,\n",
    "    clim=(-z_data.std() * clim_spacing, z_data.std() * clim_spacing),\n",
    "    xlim=(time.min(), time.max()),  # In case annotations exceed the time of the plot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create RangeToolLink between the minimap and the main EEG viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_y_disp = data_with_offset[max_ch_disp - 1].max()\n",
    "link = RangeToolLink(\n",
    "    minimap,\n",
    "    eeg_viewer,\n",
    "    axes=[\"x\", \"y\"],\n",
    "    boundsx=(None, max_t_disp),\n",
    "    boundsy=(None, max_y_disp),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the EEG Viewer with the minimap and make it a servable Panel app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eeg_with_minimap = (eeg_with_annotations + minimap).cols(1)\n",
    "\n",
    "eeg_app = pn.panel(eeg_with_minimap, min_height=650).servable(\n",
    "    target=\"main\", title=\"EEG Viewer with HoloViz and Bokeh\"\n",
    ")\n",
    "eeg_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_ch_disp = 20  # max channels to initially display\n",
    "max_t_disp = 20 # max time in seconds to initially display\n",
    "\n",
    "spacing = 2.5  # Spacing between channels\n",
    "offset = np.std(data) * spacing\n",
    "yticks = [(i * offset, ich) for i, ich in enumerate(channels)]\n",
    "y_positions = np.arange(len(channels)) * offset\n",
    "clim_spacing = 1.2\n",
    " \n",
    "hover = HoverTool(\n",
    "    tooltips=[\n",
    "        (\"Channel\", \"@channel\"),\n",
    "        (\"Time\", \"$x s\"),\n",
    "        (\"Amplitude\", \"@original_amplitude ÂµV\"),\n",
    "    ]\n",
    ")\n",
    "wheel = WheelZoomTool(\n",
    "    zoom_together=\"none\",\n",
    "    dimensions=\"width\",\n",
    "    maintain_focus=False,\n",
    ")\n",
    "\n",
    "# Create eeg_viewer\n",
    "offset_data = data + (np.arange(len(data))[:, np.newaxis] * offset)\n",
    "max_data = offset_data.max()\n",
    "\n",
    "ds = hv.Dataset(\n",
    "    (channels, time, offset_data.T, data.T),\n",
    "    kdims=[\"channel\", \"Time\"],\n",
    "    # vdims=[\"Amplitude\", \"original_amplitude\"],  # Original amplitude does not work yet with custom HoverTool in an overlay plot.\n",
    "    vdims=[\"Amplitude\"],\n",
    ")\n",
    "\n",
    "eeg_viewer = (\n",
    "    ds.to(hv.Curve, groupby=\"channel\")\n",
    "    .overlay()\n",
    "    .opts(hv.opts.Curve(color=\"black\", line_width=1, tools=[hover, wheel, \"xwheel_zoom\"]))\n",
    ")\n",
    "\n",
    "eeg_with_annotations = annotations_overlay * eeg_viewer\n",
    "\n",
    "# Style the EEG Viewer\n",
    "eeg_with_annotations = eeg_with_annotations.opts(\n",
    "    padding=0,\n",
    "    xlabel=\"Time (s)\",\n",
    "    ylabel=\"Channel\",\n",
    "    yticks=yticks,\n",
    "    show_legend=False,\n",
    "    aspect=1.5,\n",
    "    responsive=True,\n",
    "    shared_axes=False,\n",
    "    backend_opts={\n",
    "        \"x_range.bounds\": (time.min(), time.max()),\n",
    "        \"y_range.bounds\": (data.min(), max_data),\n",
    "    },\n",
    ")\n",
    "\n",
    "# # Create a hv.Curve element per chan\n",
    "# channel_curves = []\n",
    "# for i, channel_data in enumerate(data):\n",
    "#     offset_data = channel_data + (i * offset)\n",
    "#     max_data = max(offset_data.max(), max_data) # update max\n",
    "#     ds = Dataset((time, offset_data, channel_data, channels[i]), [\"Time\", \"Amplitude\", \"original_amplitude\", \"channel\"])\n",
    "#     channel_curves.append(\n",
    "#         hv.Curve(ds, \"Time\", [\"Amplitude\", \"original_amplitude\", \"channel\"]).opts(\n",
    "#             color=\"black\", line_width=1,\n",
    "#             tools=[hover, xwheel], shared_axes=False))\n",
    "\n",
    "\n",
    "\n",
    "# def set_maintain_focus(plot, element):\n",
    "#     wheel_zoom = plot.state.select(type=WheelZoomTool)\n",
    "#     if wheel_zoom:\n",
    "#         wheel_zoom[0].maintain_focus = False\n",
    "\n",
    "# # Create an overlay of curves\n",
    "# eeg_viewer = (annotations_overlay * hv.NdOverlay(channel_curves, kdims=\"Channel\"))\n",
    "# eeg_viewer = eeg_viewer.opts(\n",
    "#     padding=0, xlabel=\"Time (s)\", ylabel=\"Channel\",\n",
    "#     yticks=yticks, show_legend=False, aspect=1.5, responsive=True,\n",
    "#     shared_axes=False, xlim=(time.min(), time.max()), backend_opts={\n",
    "#         \"x_range.bounds\": (time.min(), time.max()),\n",
    "#         \"y_range.bounds\": (data.min(), max_data)},\n",
    "#     hooks=[set_maintain_focus])\n",
    "\n",
    "# # Get the y positions of the yticks to use as yaxis of minimap image\n",
    "# y_positions, _ = zip(*yticks)\n",
    "\n",
    "# Compute z-scores across time for each channel\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "# Generate the zscored image for the minimap using the y tiack positions from the eeg_viewer\n",
    "minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "\n",
    "# Style the minimap \n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\",\n",
    "    colorbar=False,\n",
    "    xlabel=\"\",\n",
    "    alpha=.5,\n",
    "    yticks=[yticks[0], yticks[-1]],\n",
    "    height=100,\n",
    "    responsive=True,\n",
    "    default_tools=[\"\"],\n",
    "    shared_axes=False,\n",
    "    clim=(-z_data.std()*clim_spacing, z_data.std()*clim_spacing),\n",
    "    xlim=(time.min(), time.max()),  # If annotations exceed the time of the plot\n",
    ")\n",
    "    \n",
    "# Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "max_y_disp = offset_data[max_ch_disp - 1].max()\n",
    "link = RangeToolLink(\n",
    "    minimap,\n",
    "    eeg_viewer,\n",
    "    axes=[\"x\", \"y\"],\n",
    "    boundsx=(None, max_t_disp),\n",
    "    boundsy=(None, max_y_disp))\n",
    "\n",
    "eeg_with_minimap = (eeg_with_annotations + minimap * annotations_overlay).cols(1)\n",
    "\n",
    "eeg_app = pn.panel(eeg_with_minimap, min_height=650).servable(\n",
    "    target=\"main\", title=\"EEG Viewer with HoloViz and Bokeh\"\n",
    ")\n",
    "eeg_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
