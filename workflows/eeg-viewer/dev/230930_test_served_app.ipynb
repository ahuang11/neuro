{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f8b68-f8fa-46f4-87cb-c84f5fee4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# HoloViz and Bokeh\n",
    "import colorcet as cc\n",
    "import holoviews as hv; hv.extension('bokeh')\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from holoviews.operation.datashader import rasterize\n",
    "from holoviews import Dataset\n",
    "from bokeh.models import HoverTool, WheelZoomTool\n",
    "import panel as pn; pn.extension(template='material')\n",
    "\n",
    "# Neuro repo\n",
    "from neurodatagen.eeg import generate_eeg_powerlaw\n",
    "from hvneuro import download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78795966-38d3-4e75-9c45-993f5c2aa543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8b555-04b8-483d-92e7-62b8d2088bbe",
   "metadata": {},
   "source": [
    "### Intake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88095b7f-c193-4d55-919e-704584cc6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset is 2.6 MB on disk\n",
    "url = \"https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf?download\"\n",
    "local_data_path = \"../../data/\"\n",
    "\n",
    "# Will not download if already present at local_data_path\n",
    "local_file_path = download_file(url, local_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88634b-189e-441a-a99a-208f10748af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(local_file_path, preload=True)\n",
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14482c4-d7f7-4358-bb1e-1cf0c6f1eec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview the channel names, types, signal ranges, and uncompressed size\n",
    "# raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb12e9-bbd5-4d5f-8d4f-1fe1e7aa77ad",
   "metadata": {},
   "source": [
    "### Gather the real timeseries annotations and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbb5d6-25af-407b-9bf6-8b5edf40d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get initial time of experiment\n",
    "orig_time = raw.annotations.orig_time\n",
    "\n",
    "# get annotations into pd df\n",
    "annotations_df = raw.annotations.to_data_frame()\n",
    "\n",
    "# Ensure the 'onset' column is in UTC timezone\n",
    "annotations_df['onset'] = annotations_df['onset'].dt.tz_localize('UTC')\n",
    "\n",
    "annotations_df['start'] = (annotations_df['onset'] - orig_time).dt.total_seconds()\n",
    "annotations_df['end'] = annotations_df['start'] + annotations_df['duration']\n",
    "\n",
    "\n",
    "unique_descriptions = annotations_df['description'].unique()\n",
    "color_map = dict(zip(unique_descriptions, cc.glasbey[:len(unique_descriptions)]))\n",
    "annotations_df['color'] = annotations_df['description'].map(color_map)\n",
    "\n",
    "# annotations_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4c977-9dc4-4931-843d-e4cf64b6dfa7",
   "metadata": {},
   "source": [
    "### Clean channel names, set sensor positions, and reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88853679-7b6d-4a3c-969d-23b813aa9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the channel names\n",
    "raw.rename_channels(lambda s: s.strip(\".\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dc2d1-7972-4b4b-9de8-c49cc03fa78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = raw.times\n",
    "channels = raw.ch_names\n",
    "\n",
    "# get the EEG data (for this data set, all channels are EEG anyways)\n",
    "eeg_indices = mne.pick_types(raw.info, eeg=True)\n",
    "data = raw.get_data(picks=eeg_indices, units={\"eeg\":\"uV\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4f900c-521f-4db8-acd2-fd7f177621e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ch_disp = 20  # max channels to initially display\n",
    "max_t_disp = 20 # max time in seconds to initially display\n",
    "\n",
    "annotation = hv.VSpan(19, 20).opts(color='yellow', alpha=.15) # example annotation (start, end) time\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Channel\", \"@channel\"),\n",
    "    (\"Time\", \"$x s\"),\n",
    "    (\"Amplitude\", \"$y ÂµV\")])\n",
    "\n",
    "channel_curves = []\n",
    "for channel, channel_data in zip(channels, data):\n",
    "    ds = Dataset((time, channel_data, channel), [\"Time\", \"Amplitude\", \"channel\"])\n",
    "    curve = hv.Curve(ds, \"Time\", [\"Amplitude\", \"channel\"], label=f'{channel}')\n",
    "    curve.opts(\n",
    "        color=\"black\",\n",
    "        line_width=1,\n",
    "        subcoordinate_y=True,\n",
    "        subcoordinate_scale=3,\n",
    "        tools=[hover])\n",
    "    channel_curves.append(curve)\n",
    "\n",
    "eeg_viewer = (annotation * hv.Overlay(channel_curves, kdims=\"Channel\"))\n",
    "eeg_viewer = eeg_viewer.opts(\n",
    "    xlabel=\"Time (s)\",\n",
    "    ylabel=\"Channel\",\n",
    "    show_legend=False,\n",
    "    responsive=True,\n",
    "    shared_axes=False,\n",
    "    aspect=2,\n",
    "    xlim=(time.min(), time.max()),\n",
    "    backend_opts={\n",
    "        \"x_range.bounds\": (time.min()-2, time.max()),\n",
    "        \"y_range.bounds\": (-2, len(channels))})\n",
    "\n",
    "y_positions = range(len(channels))\n",
    "yticks = [(i, ich) for i, ich in enumerate(channels)]\n",
    "\n",
    "z_data = zscore(data, axis=1)\n",
    "\n",
    "minimap = rasterize(hv.Image((time, y_positions, z_data), [\"Time (s)\", \"Channel\"], \"Amplitude (uV)\"))\n",
    "\n",
    "clim_mul = 3\n",
    "minimap = minimap.opts(\n",
    "    cmap=\"RdBu_r\", colorbar=False, xlabel='', alpha=.5, yticks=[yticks[0], yticks[-1]],\n",
    "    height=125, responsive=True, default_tools=[], shared_axes=False, clim=(-z_data.std()*clim_mul, z_data.std()*clim_mul))\n",
    "\n",
    "# Create RangeToolLink between the minimap and the main EEG viewer \n",
    "# max_y_disp = np.max(data[max_ch_disp-1,:] + ((max_ch_disp-1) * offset))\n",
    "RangeToolLink(minimap, eeg_viewer, axes=[\"x\", \"y\"], boundsx=(0, 20), boundsy=(-1, 10))\n",
    "\n",
    "eeg_app = pn.Column((eeg_viewer + minimap * annotation)\n",
    "eeg_app = eeg_app.opts(merge_tools=False).cols(1), min_height=650).servable(\n",
    "    target='main', title='EEG Viewer with HoloViz and Bokeh')\n",
    "eeg_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a9ff1-188b-4b29-97c2-7f7044cd5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6017c2a-0fae-4a27-9d3d-6a92997e5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136ab7d-6772-4682-83ce-3e2aae446090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
